# sniper

`sniper` 是一个基于 `tensorflow` 的分布式 `GPU` 训练框架。

## 背景

在快手商业化的工作中，我参与建设了快手商业化第一代分布式 `GPU` 训练系统。包括与 `AI` 平台合作自研的分布式训练框架 `klearn`, 离线、在线
样本流的搭建、实时交叉 `auc` 的开发等等。

`klearn` 有很多设计是很不错的。以下简单列举一些：
- 单独拆出来 `hub` 模块处理 `io` 相关逻辑, 减轻 `trainer` 的 `io` 压力。
- `trainer` 使用 `python` 与 `c++` 实现，`ps` 和 `hub` 使用 `c++` 实现，最大程度的利用了 `python` 的灵活性和 `c++` 的高性能。
- `embedding` 和网络层参数的混合同步异步更新方式。
- `trainer` 端的数据预取加速数据读取。
- 离线提前将特征拼成自定义的 `batch` 格式，加速 `io` 速度。
- `sparse` 特征通过差分进行压缩保存，减少存储以及通信量。
- `ps` 端进行 `sparse` 特征的聚合，减少 `trainer` 端的通信量。
- `ps` 异步处理 `sparse` 特征相关的参数。
- `ps` 自动负载均衡。

通过以上这些设计，以及其他很多细节的优化，`klearn` 通过构建全局的异步流水线，实现了高性能的模型训练，同时极大的提高了资源利用率。很好的
支撑了快手商业化的模型训练任务。

不过后来由于架构调整，模型训练迁移到了更新的训练框架，`klearn` 就没有再继续迭代。有时候和一些去其他公司的同事交流，发现大家还是很怀念当时
的 `klearn` 框架。

还是感觉有点可惜。 因此，参考 `klearn` 的设计思路， 我将 `ps` 和 `hub` 又用 `rust` 重新实现了一遍, 开发了 `sniper` 框架。
